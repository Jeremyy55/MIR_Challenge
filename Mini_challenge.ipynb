{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orEqVqOg1yjC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications import vgg16\n",
    "from keras.applications import vgg19\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications import mobilenet\n",
    "from keras.applications import xception\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qO1zpdVcfOPF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 138s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model1 = vgg16.VGG16(weights='imagenet', include_top=True,pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## définition et création des chemins d'accès aux données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NYU-UhdLXHg2"
   },
   "outputs": [],
   "source": [
    "#lecture de la base d'image\n",
    "data_path='../'\n",
    "files = data_path+\"GHIM-20库\"                  #chemin vers la base d'images\n",
    "features1 = []                       #Stocker les caractérstiques\n",
    "big_folder=data_path+\"features/\"               #Dossier pour stocker les caractérstiques\n",
    "if not os.path.exists(big_folder):\n",
    "  os.makedirs(big_folder)\n",
    "folder_model=data_path+\"Features_train/model/\"\n",
    "if not os.path.exists(folder_model):\n",
    "  os.makedirs(folder_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjjPeQChaGMy"
   },
   "source": [
    "## génération des caractéristiques de la base d'images \n",
    "La section ci-dessous se charge, pour chacune des images stockées dans le dossier menant aux fichiers utilisés, de récupérer les informations obtenues par la dernière couche du réseau de neurone. \n",
    "\n",
    "Cette information peut-être considéré comme une extraction des caractéristiques intéressantes de l'images car notre réseau de neurone se charge , couche après couche, de récupérer les informations utiles pour ensuite prédire la catégorie à laquelle l'image appartient. \n",
    "\n",
    "Ces vecteurs caractéristiques sont ensuites utilisées pour pouvoir comparer les images plus simplement"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mini_challenge.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
